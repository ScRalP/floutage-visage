{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4bbbe1-4d28-4bd3-a0f8-db67b568230c",
   "metadata": {},
   "source": [
    "# Projet floutage de visage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d3036-a55c-4e2b-9727-ca39b36a37a7",
   "metadata": {},
   "source": [
    "Dans la section qui suit on ajoute tous les import necéssaires au programme. <br/>\n",
    "cv2 pour OpenCV nous sert dans la capture vidéo et dans le floutage du visage. <br/>\n",
    "numpy nous sert dans l'une des deux versions de floutage. <br/>\n",
    "skimage pour les filtres qui servent à la détection de visage. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a35ce2-f1d4-4fff-914a-993978413e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import filters\n",
    "from skimage.feature import Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d63f7-207a-450c-85f8-c45b3121d9f0",
   "metadata": {},
   "source": [
    "On initialise la capture de vidéo et le détecteur de visage, on les utilisera par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c55d77-aad3-4b30-8c12-72aa8ef22145",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "trained = skimage.data.lbp_frontal_face_cascade_filename()\n",
    "detector = Cascade(trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2c190-9614-4441-8395-8d42a38e9000",
   "metadata": {},
   "source": [
    "<p>On vient ensuite faire une capture vidéo, toute les 5 images capturées on vient appliquer un traitement dessus. <br/>\n",
    "On récupère l'image en question, on vient lui appliquer un filtre pour la débruiter, ce n'est qu'après cela que l'on applique la détection de visage. <br/>\n",
    "Pour chaque visage trouvé on vient remplacer cette portion d'image par une copie d'elle même à laquelle on applique un floutage. </p>\n",
    "<p>On vient ensuite afficher l'image ainsi modifiée pour appliquer ce floutage en temps réel. Cette méthode fonctionne parfaitement bien sur des visages d'une certaine dimension. Le problème étant que si un visage est trop éloigné, ou inversement si il est trop proche, alors la détection ne s'appliquera pas. Si nous mettons une trop grande plage de détection à notre programme, il va essayer de détecter des visages même minuscules, ce qui cause de gros problèmes de performances.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584d95c5-c37b-4e0e-bb81-8e605dcb5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt = 0\n",
    "while True:\n",
    "    cpt += 1\n",
    "    if cpt%5 == 0: # Traitement tout les 5 frames\n",
    "        # Capture de la frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Débruitage de l'image\n",
    "        filtered_frame = filters.median(frame)\n",
    "\n",
    "        # Detection des visages\n",
    "        detected = detector.detect_multi_scale(filtered_frame,\n",
    "                                               scale_factor=1.2,\n",
    "                                               step_ratio=1,\n",
    "                                               min_size=(90, 90),\n",
    "                                               max_size=(200, 200))\n",
    "\n",
    "\n",
    "        # Pour tout les visages detect\n",
    "        for patch in detected:\n",
    "            r = patch['r']\n",
    "            c = patch['c']\n",
    "            width = patch['width']\n",
    "            height = patch['height']\n",
    "\n",
    "            # get the rectangle img around all the faces\n",
    "            face = filtered_frame[r:r+height, c:c+width]\n",
    "            \n",
    "            # Floutage de l'image\n",
    "            # option 1 : avec filter2D\n",
    "            #kernel = np.ones((10, 10), np.float32) / 100\n",
    "            #blur_face = cv2.filter2D(face, -1, kernel)\n",
    "\n",
    "            #option 2 : avec un filtre gaussien\n",
    "            blur_face = cv2.GaussianBlur(face, (15, 15), 8)\n",
    "            # merge this blurry rectangle to our final image\n",
    "            filtered_frame[r:r+height, c:c+width] = blur_face\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('floutage visage',filtered_frame)\n",
    "\n",
    "    # Quitter la fenetre lors de l'appui sur \"q\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558bd95-9d6d-4cb9-89c5-b54e37fef94f",
   "metadata": {},
   "source": [
    "On obtient une capture vidéo qui détecte les visages et vient appliquer un flou par dessus. <br/>\n",
    "Pour quitter la fenêtre il faut appuyer sur la touche 'q'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d84252-0ba3-4a37-a362-7da07bfb3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d9f6c-62f4-47dc-acc7-a7562e493e83",
   "metadata": {},
   "source": [
    "Une fois le programme terminé on relache la capture et on détruit la fenêtre associée."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}